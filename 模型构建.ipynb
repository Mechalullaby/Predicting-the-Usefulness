{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split,cross_val_score\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import precision_score\n",
    "from sklearn.metrics import recall_score\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn import svm\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.neural_network import MLPClassifier\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 切分数据集\n",
    "df = pd.read_csv(\"耳机.csv\")\n",
    "#df = pd.read_excel('耳机2.xlsx')\n",
    "target = df.pop(\"Helpfulness\")\n",
    "data2 = df.values\n",
    "X = data2\n",
    "Y = target\n",
    "X_train,X_test,Y_train,Y_test = train_test_split(X,Y,test_size = 0.2,random_state = 3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 描述性分析"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count    1032.000000\n",
       "mean        5.916667\n",
       "std         6.362996\n",
       "min         0.000000\n",
       "25%         2.000000\n",
       "50%         4.000000\n",
       "75%         7.000000\n",
       "max        61.000000\n",
       "Name: Relevancy, dtype: float64"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['Relevancy'].describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 用于验证Relevancy是否有用"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "data3 = df.drop('Relevancy',axis=1)\n",
    "data2 = data3.values\n",
    "X_r = data2\n",
    "X_train_r,X_test_r = train_test_split(X_r,test_size = 0.2,random_state = 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 标准化数据（标准差标准化）\n",
    "sc = StandardScaler().fit(X_train)\n",
    "X_train_std = sc.transform(X_train)\n",
    "X_test_std = sc.transform(X_test)\n",
    "# 没有R的数据\n",
    "sc = StandardScaler().fit(X_train_r)\n",
    "X_train_std_r = sc.transform(X_train_r)\n",
    "X_test_std_r = sc.transform(X_test_r)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "准确率： 0.893719806763285\n",
      "精确率： 0.8939393939393939\n",
      "召回率： 0.7972972972972973\n",
      "F1： 0.8428571428571429\n"
     ]
    }
   ],
   "source": [
    "# LR模型预测\n",
    "lr = LogisticRegression()  #初始化LogisticRegression\n",
    "lr.fit(X_train_std, Y_train)  # 调用LogisticRegression中的fit函数训练模型参数\n",
    "lr_pres = lr.predict(X_test_std) # 使用训练好的模型lr对X_test进行预测\n",
    "print('准确率：',accuracy_score(Y_test, lr_pres))\n",
    "print('精确率：',precision_score(Y_test, lr_pres))\n",
    "print('召回率：',recall_score(Y_test, lr_pres))\n",
    "print('F1：',f1_score(Y_test,lr_pres))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 改变阈值"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "ss = 1/(1+np.exp(-lr.decision_function(X_test_std)))\n",
    "ss = pd.DataFrame(ss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "阈值为0.4时准确率为：0.9033816425120773\n",
      "阈值为0.41250000000000003时准确率为：0.9033816425120773\n",
      "阈值为0.42500000000000004时准确率为：0.9082125603864735\n",
      "阈值为0.4375时准确率为：0.9082125603864735\n",
      "阈值为0.45时准确率为：0.9130434782608695\n",
      "阈值为0.4625时准确率为：0.8985507246376812\n",
      "阈值为0.475时准确率为：0.8985507246376812\n",
      "阈值为0.4875时准确率为：0.9033816425120773\n",
      "阈值为0.5时准确率为：0.893719806763285\n"
     ]
    }
   ],
   "source": [
    "#使用二分法多次尝试\n",
    "for i in np.linspace(0.4, 0.5, num=9):\n",
    "    mm = ss[0].apply(lambda x:1 if x>i else 0)\n",
    "    mm = np.array(mm)\n",
    "    print('阈值为%s时准确率为：%s'%(i, accuracy_score(Y_test, mm)))\n",
    "#得出结论阈值为0.46时可以得出较好的结果"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "准确率为：0.9130434782608695\n",
      "精确率： 0.8888888888888888\n",
      "召回率： 0.8648648648648649\n",
      "F1： 0.8767123287671232\n"
     ]
    }
   ],
   "source": [
    "mm = ss[0].apply(lambda x:1 if x>0.45 else 0)\n",
    "mm = np.array(mm)\n",
    "print('准确率为：%s'%accuracy_score(Y_test, mm))\n",
    "print('精确率：',precision_score(Y_test, mm))\n",
    "print('召回率：',recall_score(Y_test, mm))\n",
    "print('F1：',f1_score(Y_test,mm))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 对比"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "准确率： 0.8743961352657005\n",
      "精确率： 0.8529411764705882\n",
      "召回率： 0.7837837837837838\n",
      "F1： 0.8169014084507041\n"
     ]
    }
   ],
   "source": [
    "lr = LogisticRegression()  #初始化LogisticRegression\n",
    "lr.fit(X_train_std_r, Y_train)  # 调用LogisticRegression中的fit函数训练模型参数\n",
    "lr_pres = lr.predict(X_test_std_r) # 使用训练好的模型lr对X_test进行预测\n",
    "print('准确率：',accuracy_score(Y_test, lr_pres))\n",
    "print('精确率：',precision_score(Y_test, lr_pres))\n",
    "print('召回率：',recall_score(Y_test, lr_pres))\n",
    "print('F1：',f1_score(Y_test,lr_pres))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8603808812546678"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lr = LogisticRegression(max_iter=3000)\n",
    "scores = cross_val_score(lr,X,Y,cv=10,scoring='accuracy')  #cv：选择每次测试折数  accuracy：评价指标是准确度\n",
    "scores.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# AdaBoost-DT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "weak_clf_01 train acc: 0.8788\n",
      "weak_clf_02 train acc: 0.8024\n",
      "weak_clf_03 train acc: 0.5200\n",
      "weak_clf_04 train acc: 0.8024\n",
      "weak_clf_05 train acc: 0.6642\n",
      "weak_clf_06 train acc: 0.7333\n",
      "weak_clf_07 train acc: 0.6642\n",
      "weak_clf_08 train acc: 0.7152\n",
      "weak_clf_09 train acc: 0.6642\n",
      "weak_clf_10 train acc: 0.7152\n",
      "weak_clf_11 train acc: 0.6473\n",
      "weak_clf_12 train acc: 0.8776\n",
      "weak_clf_13 train acc: 0.3964\n",
      "weak_clf_14 train acc: 0.2897\n",
      "weak_clf_15 train acc: 0.7309\n",
      "weak_clf_16 train acc: 0.6642\n",
      "weak_clf_17 train acc: 0.7164\n",
      "weak_clf_18 train acc: 0.6642\n",
      "weak_clf_19 train acc: 0.7333\n",
      "weak_clf_20 train acc: 0.6291\n",
      "My AdaBoost clf train accuracy: 0.8945\n",
      "My AdaBoost clf test accuracy: 0.9034\n",
      "准确率： 0.9033816425120773\n",
      "精确率： 0.8648648648648649\n",
      "召回率： 0.8648648648648649\n",
      "F1： 0.8648648648648649\n"
     ]
    }
   ],
   "source": [
    "# Fit a simple decision tree(weak classifier) first\n",
    "clf_tree = DecisionTreeClassifier(max_depth = 2, random_state = 1)\n",
    "\n",
    "def my_adaboost_clf(Y_train, X_train, Y_test, X_test, M=20, weak_clf=DecisionTreeClassifier(max_depth = 2)):\n",
    "    n_train, n_test = len(X_train), len(X_test)\n",
    "    # Initialize weights\n",
    "    w = np.ones(n_train) / n_train\n",
    "    pred_train, pred_test = [np.zeros(n_train), np.zeros(n_test)]\n",
    "\n",
    "    for i in range(M):\n",
    "        # Fit a classifier with the specific weights\n",
    "        weak_clf.fit(X_train, Y_train, sample_weight = w)\n",
    "        pred_train_i = weak_clf.predict(X_train)\n",
    "        pred_test_i = weak_clf.predict(X_test)\n",
    "\n",
    "        # Indicator function\n",
    "        miss = [int(x) for x in (pred_train_i != Y_train)]\n",
    "        print(\"weak_clf_%02d train acc: %.4f\"\n",
    "         % (i + 1, 1 - sum(miss) / n_train))\n",
    "\n",
    "        # Error\n",
    "        err_m = np.dot(w, miss)\n",
    "        # Alpha\n",
    "        alpha_m = 0.5 * np.log((1 - err_m) / float(err_m))\n",
    "        # New weights\n",
    "        miss2 = [x if x==1 else -1 for x in miss] # -1 * y_i * G(x_i): 1 / -1\n",
    "        w = np.multiply(w, np.exp([float(x) * alpha_m for x in miss2]))\n",
    "        w = w / sum(w)\n",
    "\n",
    "        # Add to prediction\n",
    "        pred_train_i = [1 if x == 1 else -1 for x in pred_train_i]\n",
    "        pred_test_i = [1 if x == 1 else -1 for x in pred_test_i]\n",
    "        pred_train = pred_train + np.multiply(alpha_m, pred_train_i)\n",
    "        pred_test = pred_test + np.multiply(alpha_m, pred_test_i)\n",
    "\n",
    "    pred_train = (pred_train > 0) * 1\n",
    "    pred_test = (pred_test > 0) * 1\n",
    "\n",
    "    print(\"My AdaBoost clf train accuracy: %.4f\" % (sum(pred_train == Y_train) / n_train))\n",
    "    print(\"My AdaBoost clf test accuracy: %.4f\" % (sum(pred_test == Y_test) / n_test))\n",
    "\n",
    "    return pred_test\n",
    "ab = my_adaboost_clf(Y_train, X_train_std, Y_test, X_test_std)\n",
    "print('准确率：',accuracy_score(Y_test, ab))\n",
    "print('精确率：',precision_score(Y_test, ab))\n",
    "print('召回率：',recall_score(Y_test, ab))\n",
    "print('F1：',f1_score(Y_test,ab))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 对比"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "weak_clf_01 train acc: 0.8788\n",
      "weak_clf_02 train acc: 0.8024\n",
      "weak_clf_03 train acc: 0.4036\n",
      "weak_clf_04 train acc: 0.8012\n",
      "weak_clf_05 train acc: 0.6642\n",
      "weak_clf_06 train acc: 0.7152\n",
      "weak_clf_07 train acc: 0.6715\n",
      "weak_clf_08 train acc: 0.7152\n",
      "weak_clf_09 train acc: 0.6473\n",
      "weak_clf_10 train acc: 0.6642\n",
      "weak_clf_11 train acc: 0.7333\n",
      "weak_clf_12 train acc: 0.6376\n",
      "weak_clf_13 train acc: 0.7333\n",
      "weak_clf_14 train acc: 0.5564\n",
      "weak_clf_15 train acc: 0.6630\n",
      "weak_clf_16 train acc: 0.7491\n",
      "weak_clf_17 train acc: 0.7224\n",
      "weak_clf_18 train acc: 0.2400\n",
      "weak_clf_19 train acc: 0.6121\n",
      "weak_clf_20 train acc: 0.5358\n",
      "My AdaBoost clf train accuracy: 0.8861\n",
      "My AdaBoost clf test accuracy: 0.8744\n",
      "准确率： 0.8743961352657005\n",
      "精确率： 0.8428571428571429\n",
      "召回率： 0.7972972972972973\n",
      "F1： 0.8194444444444444\n"
     ]
    }
   ],
   "source": [
    "ab = my_adaboost_clf(Y_train, X_train_std_r, Y_test, X_test_std_r)\n",
    "print('准确率：',accuracy_score(Y_test, ab))\n",
    "print('精确率：',precision_score(Y_test, ab))\n",
    "print('召回率：',recall_score(Y_test, ab))\n",
    "print('F1：',f1_score(Y_test,ab))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SVM(支持向量机) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Linear model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "准确率： 0.8888888888888888\n",
      "精确率： 0.8695652173913043\n",
      "召回率： 0.8108108108108109\n",
      "F1： 0.8391608391608392\n"
     ]
    }
   ],
   "source": [
    "svm_l = svm.SVC(kernel='linear', C=2)\n",
    "svm_l.fit(X_train_std, Y_train)\n",
    "y_test_pred_l = svm_l.predict(X_test_std)\n",
    "print('准确率：',accuracy_score(Y_test, y_test_pred_l))\n",
    "print('精确率：',precision_score(Y_test, y_test_pred_l))\n",
    "print('召回率：',recall_score(Y_test, y_test_pred_l))\n",
    "print('F1：',f1_score(Y_test,y_test_pred_l))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "准确率： 0.855072463768116\n",
      "精确率： 0.84375\n",
      "召回率： 0.7297297297297297\n",
      "F1： 0.7826086956521738\n"
     ]
    }
   ],
   "source": [
    "# 对比\n",
    "svm_l.fit(X_train_std_r, Y_train)\n",
    "y_test_pred_l = svm_l.predict(X_test_std_r)\n",
    "print('准确率：',accuracy_score(Y_test, y_test_pred_l))\n",
    "print('精确率：',precision_score(Y_test, y_test_pred_l))\n",
    "print('召回率：',recall_score(Y_test, y_test_pred_l))\n",
    "print('F1：',f1_score(Y_test,y_test_pred_l))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Random Forest(随机森林)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "准确率： 0.8985507246376812\n",
      "精确率： 0.8441558441558441\n",
      "召回率： 0.8783783783783784\n",
      "F1： 0.8609271523178808\n"
     ]
    }
   ],
   "source": [
    "# Building a random forest\n",
    "RF_class = RandomForestClassifier(n_estimators=25, min_samples_leaf=15, random_state=1234)\n",
    "# Random forest fitting\n",
    "RF_class.fit(X_train_std, Y_train)\n",
    "# Model predictions on the test set\n",
    "RFclass_pred = RF_class.predict(X_test_std)\n",
    "print('准确率：',accuracy_score(Y_test, RFclass_pred))\n",
    "print('精确率：',precision_score(Y_test, RFclass_pred))\n",
    "print('召回率：',recall_score(Y_test, RFclass_pred))\n",
    "print('F1：',f1_score(Y_test,RFclass_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "准确率： 0.8695652173913043\n",
      "精确率： 0.8309859154929577\n",
      "召回率： 0.7972972972972973\n",
      "F1： 0.8137931034482759\n"
     ]
    }
   ],
   "source": [
    "# 对比\n",
    "RF_class.fit(X_train_std_r, Y_train)\n",
    "# Model predictions on the test set\n",
    "RFclass_pred = RF_class.predict(X_test_std_r)\n",
    "print('准确率：',accuracy_score(Y_test, RFclass_pred))\n",
    "print('精确率：',precision_score(Y_test, RFclass_pred))\n",
    "print('召回率：',recall_score(Y_test, RFclass_pred))\n",
    "print('F1：',f1_score(Y_test,RFclass_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8575149365197909"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rfc = RandomForestClassifier(n_estimators=25,random_state=15)\n",
    "score_pre = cross_val_score(rfc,X,Y,cv=10).mean()\n",
    "score_pre"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 朴素贝叶斯"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "准确率： 0.893719806763285\n",
      "精确率： 0.8714285714285714\n",
      "召回率： 0.8243243243243243\n",
      "F1： 0.8472222222222222\n"
     ]
    }
   ],
   "source": [
    "from sklearn.naive_bayes import BernoulliNB\n",
    "nb = BernoulliNB(alpha=0.1,binarize = 5,fit_prior=True)\n",
    "nb.fit(X_train, Y_train)\n",
    "nb_pred = nb.predict(X_test)\n",
    "print('准确率：',accuracy_score(Y_test, nb_pred))\n",
    "print('精确率：',precision_score(Y_test, nb_pred))\n",
    "print('召回率：',recall_score(Y_test, nb_pred))\n",
    "print('F1：',f1_score(Y_test,nb_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "准确率： 0.8454106280193237\n",
      "精确率： 0.9038461538461539\n",
      "召回率： 0.6351351351351351\n",
      "F1： 0.746031746031746\n"
     ]
    }
   ],
   "source": [
    "from sklearn.naive_bayes import GaussianNB\n",
    "nb = GaussianNB()\n",
    "nb.fit(X_train_std, Y_train)\n",
    "nb_pred = nb.predict(X_test_std)\n",
    "print('准确率：',accuracy_score(Y_test, nb_pred))\n",
    "print('精确率：',precision_score(Y_test, nb_pred))\n",
    "print('召回率：',recall_score(Y_test, nb_pred))\n",
    "print('F1：',f1_score(Y_test,nb_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "准确率： 0.8599033816425121\n",
      "精确率： 0.9411764705882353\n",
      "召回率： 0.6486486486486487\n",
      "F1： 0.7680000000000001\n"
     ]
    }
   ],
   "source": [
    "nb.fit(X_train_r, Y_train)\n",
    "nb_pred = nb.predict(X_test_r)\n",
    "print('准确率：',accuracy_score(Y_test, nb_pred))\n",
    "print('精确率：',precision_score(Y_test, nb_pred))\n",
    "print('召回率：',recall_score(Y_test, nb_pred))\n",
    "print('F1：',f1_score(Y_test,nb_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "神经元个数=20，准确率：0.899\n",
      "神经元个数=21，准确率：0.899\n",
      "神经元个数=22，准确率：0.899\n",
      "神经元个数=23，准确率：0.899\n",
      "神经元个数=24，准确率：0.894\n",
      "神经元个数=25，准确率：0.899\n",
      "神经元个数=26，准确率：0.894\n",
      "神经元个数=27，准确率：0.894\n",
      "神经元个数=28，准确率：0.899\n",
      "神经元个数=29，准确率：0.894\n",
      "神经元个数=30，准确率：0.894\n",
      "神经元个数=31，准确率：0.889\n",
      "神经元个数=32，准确率：0.894\n",
      "神经元个数=33，准确率：0.894\n",
      "神经元个数=34，准确率：0.889\n",
      "神经元个数=35，准确率：0.899\n",
      "神经元个数=36，准确率：0.894\n",
      "神经元个数=37，准确率：0.889\n",
      "神经元个数=38，准确率：0.894\n",
      "神经元个数=39，准确率：0.894\n",
      "神经元个数=40，准确率：0.894\n",
      "神经元个数=41，准确率：0.889\n",
      "神经元个数=42，准确率：0.894\n",
      "神经元个数=43，准确率：0.894\n",
      "神经元个数=44，准确率：0.884\n",
      "神经元个数=45，准确率：0.889\n",
      "神经元个数=46，准确率：0.894\n",
      "神经元个数=47，准确率：0.889\n",
      "神经元个数=48，准确率：0.889\n",
      "神经元个数=49，准确率：0.889\n"
     ]
    }
   ],
   "source": [
    "# 神经元个数\n",
    "for unit in range(20,20):\n",
    "    # 激活函数：relu, logistic, tanh\n",
    "    # 优化算法：lbfgs, sgd, adam。adam适用于较大的数据集，lbfgs适用于较小的数据集。\n",
    "    #初始化模型\n",
    "    ann_model = MLPClassifier(hidden_layer_sizes=[unit], activation='logistic', solver='adam',max_iter=1000, random_state=0)\n",
    "    #训练模型\n",
    "    ann_model.fit(X_train_std, Y_train)\n",
    "    print('神经元个数={}，准确率：{:.3f}'.format(unit, ann_model.score(X_test_std, Y_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "准确率： 0.9033816425120773\n",
      "精确率： 0.8461538461538461\n",
      "召回率： 0.8918918918918919\n",
      "F1： 0.868421052631579\n"
     ]
    }
   ],
   "source": [
    "aaaa = 31\n",
    "ann_model = MLPClassifier(hidden_layer_sizes=[aaaa], activation='logistic', solver='adam',max_iter=1000, random_state=0)\n",
    "#训练模型\n",
    "ann_model.fit(X_train, Y_train)\n",
    "ann = ann_model.predict(X_test)\n",
    "print('准确率：',accuracy_score(Y_test, ann))\n",
    "print('精确率：',precision_score(Y_test, ann))\n",
    "print('召回率：',recall_score(Y_test, ann))\n",
    "print('F1：',f1_score(Y_test,ann))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "准确率： 0.8792270531400966\n",
      "精确率： 0.855072463768116\n",
      "召回率： 0.7972972972972973\n",
      "F1： 0.8251748251748252\n"
     ]
    }
   ],
   "source": [
    "# 对比\n",
    "ann_model.fit(X_train_r, Y_train)\n",
    "ann = ann_model.predict(X_test_r)\n",
    "print('准确率：',accuracy_score(Y_test, ann))\n",
    "print('精确率：',precision_score(Y_test, ann))\n",
    "print('召回率：',recall_score(Y_test, ann))\n",
    "print('F1：',f1_score(Y_test,ann))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 奇怪的集成学习"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LR+AdaBoost+ANN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "weak_clf_01 train acc: 0.8788\n",
      "weak_clf_02 train acc: 0.8024\n",
      "weak_clf_03 train acc: 0.5200\n",
      "weak_clf_04 train acc: 0.8024\n",
      "weak_clf_05 train acc: 0.6642\n",
      "weak_clf_06 train acc: 0.7333\n",
      "weak_clf_07 train acc: 0.6642\n",
      "weak_clf_08 train acc: 0.7152\n",
      "weak_clf_09 train acc: 0.6642\n",
      "weak_clf_10 train acc: 0.7152\n",
      "weak_clf_11 train acc: 0.6473\n",
      "weak_clf_12 train acc: 0.8776\n",
      "weak_clf_13 train acc: 0.3964\n",
      "weak_clf_14 train acc: 0.2897\n",
      "weak_clf_15 train acc: 0.7309\n",
      "weak_clf_16 train acc: 0.6642\n",
      "weak_clf_17 train acc: 0.7164\n",
      "weak_clf_18 train acc: 0.6642\n",
      "weak_clf_19 train acc: 0.7333\n",
      "weak_clf_20 train acc: 0.6291\n",
      "My AdaBoost clf train accuracy: 0.8945\n",
      "My AdaBoost clf test accuracy: 0.9034\n"
     ]
    }
   ],
   "source": [
    "lr = mm\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "准确率为：0.9178743961352657\n",
      "精确率： 0.88\n",
      "召回率： 0.8918918918918919\n",
      "F1： 0.8859060402684563\n"
     ]
    }
   ],
   "source": [
    "el = lr+ann+ab\n",
    "el = pd.DataFrame(el)\n",
    "el= el[0].apply(lambda x:1 if x>1.5 else 0)\n",
    "el = np.array(el)\n",
    "print('准确率为：%s'%accuracy_score(Y_test, el))\n",
    "print('精确率：',precision_score(Y_test, el))\n",
    "print('召回率：',recall_score(Y_test, el))\n",
    "print('F1：',f1_score(Y_test,el))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "9178f8153a60bf9c54f3989386f43dd42cf5811dfd22b6eac33b59addae46f26"
  },
  "kernelspec": {
   "display_name": "Python 3.6.8 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
